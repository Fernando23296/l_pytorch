{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYTORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceso de aprendizaje:\n",
    "* Forward pass\n",
    "* Backpropagation\n",
    "* Optimizacion\n",
    "\n",
    "<br>\n",
    "Usaremos tensores,\n",
    "Recordando:\n",
    "\n",
    "* Scalar\n",
    "* Vector\n",
    "* Matrix\n",
    "* Tensor\n",
    "\n",
    "La gradiente es un vector, tendra la magnitud y direccion de movimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensor (y listas numpy) vs listas python\n",
    "Si bien una lista de objetos numéricos es bastante parecido a un tensor de Pytorch (o una lista numpy), en realidad son completamente diferentes. Las listas de Python o las tuplas de números son\n",
    "colecciones de objetos de Python que se asignan individualmente en la memoria. Los tensores PyTorch o las matrices NumPy, por otro lado, son vistas sobre (típicamente) bloques de memoria contiguos.\n",
    "![](img/tensor_list.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_1 = torch.ones(2,2)\n",
    "tensor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7504, 0.8109],\n",
       "        [0.9486, 0.0973]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2=torch.Tensor(2,2)\n",
    "tensor_2.uniform_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7504, 0.8109],\n",
       "        [0.9486, 0.0973]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5825, 0.3472],\n",
       "        [0.8926, 0.3114]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_c = torch.rand(2,2)\n",
    "tensor_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3329, 1.1581],\n",
       "        [1.8412, 0.4087]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result =  tensor_2 + tensor_c\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imprime la forma del tensor\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3329],\n",
       "        [1.1581],\n",
       "        [1.8412],\n",
       "        [0.4087]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped = result.view(4,1)\n",
    "reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3329, 1.1581, 1.8412, 0.4087]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped2 =  result.view(1,4)\n",
    "reshaped2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points =  torch.tensor([[1.0,2.0],[3.0,4.0]])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors y Storage\n",
    "Los valores se asignan en fragmentos contiguos de memoria, administrados por instancias de torch.storage. Un Storage es una matriz unidimensional de datos numéricos, es decir, un bloque contiguo de memoria que contiene números de un tipo dado. Tensor Storage es capaz de indexarse en ese almacenamiento utilizando un desplazamiento y zancadas por dimensión.\n",
    "Múltiples tensores pueden indexar el mismo almacenamiento, incluso si se indexan en los datos de manera diferente. Sin embargo, la memoria subyacente solo se asigna una vez, por lo que la creación de vistas tensoras alternativas en los datos se puede hacer rápidamente, sin importar el tamaño de los datos administrados por la instancia de Storage.\n",
    "![](img/tensor_storage.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 4.0\n",
       " 2.0\n",
       " 1.0\n",
       " 3.0\n",
       " 5.0\n",
       "[torch.FloatStorage of size 6]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Veamos cómo funciona la indexación en el almacenamiento en la práctica con nuestros puntos 2D.\n",
    "Se puede acceder al almacenamiento de un tensor determinado utilizando la propiedad\n",
    "'''\n",
    "prueba_storage = torch.tensor([[1.0,4.0],[2.0,1.0],[3.0,5.0]])\n",
    "prueba_storage.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque el tensor informa que tiene 3 filas y 2 columnas, el almacenamiento es una matriz contigua de tamaño 6. En este sentido, el tensor simplemente sabe cómo traducir un par de índices en una ubicación en el almacenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride\n",
    "Para indexar en un almacenamiento, los tensores se basan en unos pocos datos que, junto con su almacenamiento, los definen inequívocamente: size (tamaño), storage offset (desplazamiento de almacenamiento) y strides (zancadas). El tamaño (o shape (forma) en NumPy) es una tupla que indica cuántos elementos en cada dimensión representa el tensor. El storage offset (desplazamiento de almacenamiento) es el índice en el almacenamiento correspondiente al primer elemento en el tensor. Stride es el número de elementos en el almacenamiento que deben omitirse para obtener el siguiente elemento a lo largo de cada dimensión.\n",
    "![](img/tensor_strides.png)\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "* stride[0] = numero de saltos en el storage para llegar a la siguiente fila\n",
    "* stride[1] = numeor de saltos para llegar a la siguiente columna\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "La mejor manera es visualizarlo en una transpuesta:\n",
    "<br>\n",
    "\n",
    "\n",
    "![](img/tensor_t_strides.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba_xd = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "prueba_xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba_xd.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 5],\n",
       "        [2, 4, 6]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba_xd.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba_xd.t().stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los strides (pasos) son una lista de enteros: el stride k representa el salto en la memoria necesario para pasar de un elemento al siguiente en la dimensión k del Tensor. Este concepto hace posible realizar muchas operaciones de tensor de manera eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba_stride = torch.Tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "prueba_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba_stride.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  6.],\n",
       "        [ 2.,  7.],\n",
       "        [ 3.,  8.],\n",
       "        [ 4.,  9.],\n",
       "        [ 5., 10.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_prueba_stride = prueba_stride.t()\n",
    "tr_prueba_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_prueba_stride.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x = torch.tensor([1,2,3,4])\n",
    "tensor_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4]]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ej_uns1 = torch.unsqueeze(tensor_x,0)\n",
    "ej_uns1,ej_uns1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ej_uns2 = torch.unsqueeze(tensor_x,1)\n",
    "ej_uns2,ej_uns2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y = torch.tensor([[1,2],[3,4]])\n",
    "tensor_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2],\n",
       "          [3, 4]]]), torch.Size([1, 2, 2]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y_uns1 = torch.unsqueeze(tensor_y,-3)\n",
    "tensor_y_uns1,tensor_y_uns1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1],\n",
       "          [2]],\n",
       " \n",
       "         [[3],\n",
       "          [4]]]), torch.Size([2, 2, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_y_uns2 = torch.unsqueeze(tensor_y,2)\n",
    "tensor_y_uns2,tensor_y_uns2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra (Flatten,Reshape,Squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([[1,1,1],\n",
    "                [2,2,2],\n",
    "                [3,3,3],\n",
    "                [4,4,4]],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.],\n",
       "        [4., 4., 4.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rango del tensor:\n",
    "len(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Para saber el numero de elementos dentro del tensor, multiplicamos\n",
    "sus dimensiones\n",
    "'''\n",
    "torch.tensor(t.shape).prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.],\n",
       "        [4., 4., 4.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Podemos cambiar la forma del tensor, tomando como relacion factores\n",
    "del numero de elementos dentro del tensor.\n",
    "Eje: 12 -> (3*4),(2*6),(1*12)\n",
    "'''\n",
    "t.reshape(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 2.],\n",
       "        [2., 2., 3., 3.],\n",
       "        [3., 4., 4., 4.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 2., 2., 2.],\n",
       "        [3., 3., 3., 4., 4., 4.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(2,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4.]])\n",
      "torch.Size([1, 12])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(t.reshape(1,12))\n",
    "print(t.reshape(1,12).shape)\n",
    "print(len(t.reshape(1,12).shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4.])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Squeeze -> apretar\n",
    "Reduce una dimension\n",
    "'''\n",
    "\n",
    "print(t.reshape(1,12).squeeze())\n",
    "sq = t.reshape(1,12).squeeze()\n",
    "print(len(sq.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4.]])\n",
      "torch.Size([1, 12])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(sq.unsqueeze(dim=0))\n",
    "# lo de abajo es lo mismo que lo de arriba\n",
    "#print(torch.unsqueeze(sq,0))\n",
    "#Se recupera una dimension\n",
    "print(t.reshape(1,12).squeeze().unsqueeze(dim=0).shape)\n",
    "print(len(t.reshape(1,12).squeeze().unsqueeze(dim=0).shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entendiendo flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    t = t.reshape(1,-1)\n",
    "    t = t.squeeze()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [2., 2., 2.],\n",
       "         [3., 3., 3.],\n",
       "         [4., 4., 4.]]),\n",
       " tensor([1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4.]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, flatten(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [2., 2., 2.],\n",
       "         [3., 3., 3.],\n",
       "         [4., 4., 4.]]),\n",
       " tensor([[1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4.]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, t.reshape(1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12]), torch.Size([1, 12]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten(t).shape,t.reshape(1,12).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4]), tensor([[1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4]]), torch.Size([4, 1]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x = torch.tensor([1,2,3,4])\n",
    "tensor_x, torch.unsqueeze(tensor_x,1),torch.unsqueeze(tensor_x,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
